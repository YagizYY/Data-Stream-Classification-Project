#%%
import os

#%%
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import time
np.set_printoptions(suppress=True)
from skmultiflow.data import AGRAWALGenerator, SEAGenerator
from skmultiflow.trees import HoeffdingTreeClassifier
from skmultiflow.drift_detection import DDM
from skmultiflow.meta import AdaptiveRandomForestClassifier
from skmultiflow.meta import StreamingRandomPatchesClassifier
from skmultiflow.meta import DynamicWeightedMajorityClassifier
from skmultiflow.lazy import SAMKNNClassifier


#%% PART 3

# generate 100,000 data instances for each 
##  The number of features (X) and the number of target values (y) generated by the AGRAWALGenerator and SEAGenerator classes in scikit-multiflow depends on the specific dataset and its configuration.


# The below code is generating datasets using AGRAWALGenerator and SEAGenerator classes, and saving
# them as CSV files. It also reads in pre-existing datasets (spam.csv, elec.csv, agrawal_dt.csv,
# sead_dt.csv) and assigns the feature and target variables to X and y variables for each dataset.
agrawal_dt = pd.DataFrame(columns=["X1","X2","X3","X4","X5","X6",
                                        "X7","X8","X9","Y"])
agrawal_generator = AGRAWALGenerator()

for i in range(100000):
    X, y = agrawal_generator.next_sample()
    agrawal_dt.loc[i, "X1"] = X[0, 0]
    agrawal_dt.loc[i, "X2"] = X[0, 1]
    agrawal_dt.loc[i, "X3"] = X[0, 2]
    agrawal_dt.loc[i, "X4"] = X[0, 3]
    agrawal_dt.loc[i, "X5"] = X[0, 4]
    agrawal_dt.loc[i, "X6"] = X[0, 5]
    agrawal_dt.loc[i, "X7"] = X[0, 6]
    agrawal_dt.loc[i, "X8"] = X[0, 7]
    agrawal_dt.loc[i, "X9"] = X[0, 8]
    agrawal_dt.loc[i, "Y"] = y[0]

sea_generator = SEAGenerator()
sead_dt = pd.DataFrame(columns=["X1","X2","X3","Y"])

for i in range(100000):
    X, y = sea_generator.next_sample()
    sead_dt.loc[i, "X1"] = X[0, 0]
    sead_dt.loc[i, "X2"] = X[0, 1]
    sead_dt.loc[i, "X3"] = X[0, 2]
    sead_dt.loc[i, "Y"] = y[0] 

sead_dt.to_csv("C:/Users/yagiz/Desktop/4-2/GE-461/DataStream/datasets/sead_dt.csv", index=False)

agrawal_dt.to_csv("C:/Users/yagiz/Desktop/4-2/GE-461/DataStream/datasets/agrawal_dt.csv", index=False)

spam = pd.read_csv("C:/Users/yagiz/Desktop/4-2/GE-461/DataStream/Datasets/spam.csv")

electric = pd.read_csv("C:/Users/yagiz/Desktop/4-2/GE-461/DataStream/Datasets/elec.csv")

agrawal_dt = pd.read_csv("C:/Users/yagiz/Desktop/4-2/GE-461/DataStream/datasets/agrawal_dt.csv")

sead_dt = pd.read_csv("C:/Users/yagiz/Desktop/4-2/GE-461/DataStream/datasets/sead_dt.csv")

X_agrawal = agrawal_dt.drop(columns=["Y"]).values
y_agrawal = agrawal_dt["Y"].values

X_sead = sead_dt.drop(columns=["Y"]).values
y_sead = sead_dt["Y"].values

X_electric = electric.drop(columns=["target"]).values
y_electric = electric["target"].values

X_spam = spam.drop(columns=["target"]).values
y_spam = spam["target"].values

#%% PART 4.2

def stream_classifer(X, y, Classifier, Method, Dataset, Number):
    """
    The function `stream_classifier` takes in data, a classifier, and a concept drift detector, and
    returns the accuracy and run time of the classifier on the data, as well as a plot of the accuracy
    per window.
    
    :param X: The input data for the classifier, in the form of a numpy array
    :param y: The target variable or labels for the input data X
    :param Classifier: The machine learning classifier to be used for the streaming classification task
    :param Method: The machine learning method being used (e.g. decision tree, logistic regression,
    etc.)
    :param Dataset: The name of the dataset being used for the streaming classification task
    :param Number: This parameter is a string that represents the number or identifier which is used to label the plots and results to differentiate them from other
    experiments
    :return: a tuple containing the accuracy, run time, result, and prediction.
    """
  
    start=time.time()

    classifier = Classifier
    
    # Initialize the DDM concept drift detector
    ddm = DDM()
    #adwin = ADWIN(delta=0.01)

    result = np.array([])
    prediction = np.array([])
   
    for i in range(len(X)):

        # Predict using the model -> test
        y_pred = classifier.predict(X[i].reshape(1, -1))

        # check if the prediction is correct
        if y[i] == y_pred:
            result = np.append(result, 1)
        else:
            result = np.append(result, 0)
            
        prediction = np.append(prediction, y_pred)
            
        # Update the model -> train
        classifier.partial_fit(X[i].reshape(1, -1), y[i].reshape(1,))

        # Update the concept drift detector
        ddm.add_element(y[i])

        # Check if concept drift detected. If yes reset the model's parameters.
        if ddm.detected_change():
            classifier = Classifier

    accuracy = round(100*(np.sum(result)/len(result)), 2)
    
    my_dt = pd.DataFrame(result, columns=["result"])
    my_dt["index"] = my_dt.index

    num_window = len(my_dt)//20

    my_windows = []
    for i in range(0, len(my_dt), num_window):
        my_windows.append(i)

    my_windows = my_windows[:-1]

    my_dt["window"] = 0

    for i in range(len(my_windows)):
        my_dt.loc[my_dt['index'] >= my_windows[i], 'window'] = i+1

    plotter = my_dt.groupby("window")["result"].mean().reset_index()
    
    end=time.time() 
    
    run_time = round(end-start)

    plt.clf()
    fig, ax = plt.subplots(figsize=((5,5)))
    ax.plot(plotter["window"], plotter["result"],
    marker="v"
    , linestyle="--"
    , color="r")


    ax.set_xticks(range(1,(1+len(plotter["window"]))))
    ax.set_xticklabels(plotter["window"])
    
    ax.set_xlabel("Window number")
    ax.set_ylabel("Accuracy")
    ax.set_title(Number + "Accuracy per Window for " + Method + " on " + Dataset)
    
    plt.show()
    
    return(accuracy, run_time, result, prediction)

#%% PART 4.1 - 4.2 - 5
# Apply the following streaming classification algorithms to the datasets and report the accuracy and run time of each algorithm on each dataset.
  
arf = AdaptiveRandomForestClassifier(random_state=1, n_estimators=5)
arf_el = stream_classifer(X_electric, y_electric, arf, "ARF", "Electric", "(1)")
 

  
print("Overal Accuracy = %" + str(arf_el[0]) + "\n Run Time (sec) =  " + str(arf_el[1]))
 

### Streaming Agnostic Model with k-Nearest Neighbors (SAM-kNN),

  
samknn = SAMKNNClassifier()
sam_el = stream_classifer(X_electric, y_electric, samknn, "SAM-kNN", "Electric", "(2)")
 

  
print("Overal Accuracy = %" + str(sam_el[0]) + "\n Run Time (sec) =  " + str(sam_el[1]))
 

### Streaming Random Patches (SRP),

  
srp = StreamingRandomPatchesClassifier(random_state=1, disable_drift_detection=True, n_estimators = 5)
srp_el = stream_classifer(X_electric, y_electric, srp, "SRP", "Electric", "(3)")
 

print("Overal Accuracy = %" + str(srp_el[0]) + "\n Run Time (sec) =  " + str(srp_el[1]))
 
### Dynamic Weighted Majority (DWM),

dwm = DynamicWeightedMajorityClassifier(base_estimator=HoeffdingTreeClassifier(), n_estimators = 5)
dwm_el = stream_classifer(X_electric, y_electric, dwm, "DWM", "Electric", "(4)")
 

print("Overal Accuracy = %" + str(dwm_el[0]) + "\n Run Time (sec) =  " + str(dwm_el[1]))
 
### Ensemble Method,

data = {"samknn": sam_el[3], "arf": arf_el[3], "srp": srp_el[3], "dwm": dwm_el[3]}

ensemble_dt = pd.DataFrame(data)

most_occurings = ensemble_dt.mode(axis=1)
ensemble_dt["ensemble"] = most_occurings[0]

ensemble_dt["index"] = ensemble_dt.index

ensemble_sead = ensemble_dt["ensemble"].to_numpy()

ensemble_dt["target"] = y_sead
ensemble_dt["result"] = 0
ensemble_dt.loc[ensemble_dt["ensemble"] == ensemble_dt["target"], "result"] = 1

num_window = len(ensemble_dt)//20

my_windows = []
for i in range(0, len(ensemble_dt), num_window):
    my_windows.append(i)

my_windows = my_windows[:-1]

ensemble_dt["window"] = 0

for i in range(len(my_windows)):
    ensemble_dt.loc[ensemble_dt['index'] >= my_windows[i], 'window'] = i+1

plotter = ensemble_dt.groupby("window")["result"].mean().reset_index()

plt.clf()
fig, ax = plt.subplots(figsize=((5,5)))
ax.plot(plotter["window"], plotter["result"],
marker="v"
, linestyle="--"
, color="r")


ax.set_xticks(range(1,(1+len(plotter["result"]))))
#ax.set_xticklabels(plotter["ensemble"])


ax.set_xlabel("Window number")
ax.set_ylabel("Accuracy")
ax.set_title("(5) Accuracy per Window for Ensemble Method on Electric Dataset")

plt.show()
 
ensemble_electric["target"] = y_electric
accuracy = round(100*(ensemble_electric[ensemble_electric["ensemble"] == ensemble_electric["target"]].shape[0]/ensemble_electric.shape[0]), 2)

print("Overal Accuracy = %" + str(accuracy) + "\n Run Time (sec) =  " + str(arf_el[1] + dwm_el[1] + srp_el[1]+ sam_el[1]))
 

## For spam dataset,

### Adaptive Random Forest (ARF),

arf = AdaptiveRandomForestClassifier(random_state=1, n_estimators=5)
arf_spam = stream_classifer(X_spam, y_spam, arf, "ARF", "Spam", "(6)")
 
print("Overal Accuracy = %" + str(arf_spam[0]) + "\n Run Time (sec) =  " + str(arf_spam[1]))
 
### Streaming Agnostic Model with k-Nearest Neighbors (SAM-kNN),

start=time.time()
samknn = SAMKNNClassifier()
sam_spam = stream_classifer(X_spam, y_spam, samknn, "SAM-kNN", "Spam", "(7)")
 
print("Overal Accuracy = %" + str(sam_spam[0]) + "\n Run Time (sec) =  " + str(sam_spam[1]))
end=time.time() 
print(end-start)
### Streaming Random Patches (SRP),

start=time.time()
srp = StreamingRandomPatchesClassifier(random_state=1, disable_drift_detection=True, n_estimators = 3)
srp_spam = stream_classifer(X_spam, y_spam, srp, "SRP", "Spam", "(8)")
srp_spam[2]
 
print("Overal Accuracy = %" + str(srp_spam[0]) + "\n Run Time (sec) =  " + str(srp_spam[1]))
end=time.time() 
print(end-start)


start=time.time()
srp = StreamingRandomPatchesClassifier(random_state=1, disable_drift_detection=True, n_estimators = 5)
srp_spam = stream_classifer(X_spam, y_spam, srp, "SRP", "Spam", "(8)")
srp_spam[2]
 
print("Overal Accuracy = %" + str(srp_spam[0]) + "\n Run Time (sec) =  " + str(srp_spam[1]))
end=time.time() 
print(end-start)
 
### Dynamic Weighted Majority (DWM),

start=time.time()
dwm = DynamicWeightedMajorityClassifier(base_estimator=HoeffdingTreeClassifier(), n_estimators = 3)
dwm_spam = stream_classifer(X_spam, y_spam, dwm, "DWM", "Spam", "(9)")
dwm_spam[2]
  
print("Overal Accuracy = %" + str(dwm_spam[0]) + "\n Run Time (sec) =  " + str(dwm_spam[1]))
end=time.time() 
print(end-start)

start=time.time()
dwm = DynamicWeightedMajorityClassifier(base_estimator=HoeffdingTreeClassifier())
dwm_spam = stream_classifer(X_spam, y_spam, dwm, "DWM", "Spam", "(9)")
dwm_spam[2]
  
print("Overal Accuracy = %" + str(dwm_spam[0]) + "\n Run Time (sec) =  " + str(dwm_spam[1]))
end=time.time() 
print(end-start)
 
### Ensemble Method,

data = {"samknn": sam_spam[3], "arf": arf_spam[3], "srp": srp_spam[3], "dwm": dwm_spam[3]}

ensemble_dt = pd.DataFrame(data)

most_occurings = ensemble_dt.mode(axis=1)
ensemble_dt["ensemble"] = most_occurings[0]

ensemble_dt["index"] = ensemble_dt.index

ensemble_sead = ensemble_dt["ensemble"].to_numpy()

ensemble_dt["target"] = y_sead
ensemble_dt["result"] = 0
ensemble_dt.loc[ensemble_dt["ensemble"] == ensemble_dt["target"], "result"] = 1

num_window = len(ensemble_dt)//20

my_windows = []
for i in range(0, len(ensemble_dt), num_window):
    my_windows.append(i)

my_windows = my_windows[:-1]

ensemble_dt["window"] = 0

for i in range(len(my_windows)):
    ensemble_dt.loc[ensemble_dt['index'] >= my_windows[i], 'window'] = i+1

plotter = ensemble_dt.groupby("window")["result"].mean().reset_index()

plt.clf()
fig, ax = plt.subplots(figsize=((5,5)))
ax.plot(plotter["window"], plotter["result"],
marker="v"
, linestyle="--"
, color="r")


ax.set_xticks(range(1,(1+len(plotter["result"]))))
#ax.set_xticklabels(plotter["ensemble"])


ax.set_xlabel("Window number")
ax.set_ylabel("Accuracy")
ax.set_title("(10) Accuracy per Window for Ensemble Method on Spam Dataset")

plt.show()
  
ensemble_dt["target"] = y_electric
accuracy = round(100*(ensemble_dt[ensemble_dt["ensemble"] == ensemble_dt["target"]].shape[0]/ensemble_dt.shape[0]), 2)

print("Overal Accuracy = %" + str(accuracy) + "\n Run Time (sec) =  " + str(arf_spam[1] + dwm_spam[1] + srp_spam[1]+ sam_spam[1]))
 
## For aggrawal dataset,

### Adaptive Random Forest (ARF),

arf = AdaptiveRandomForestClassifier(random_state=1, n_estimators=5)
arf_agrawal = stream_classifer(X_agrawal, y_agrawal, arf, "ARF", "Agrawal", "(11)")
 
print("Overal Accuracy = %" + str(arf_agrawal[0]) + "\n Run Time (sec) =  " + str(arf_agrawal[1]))
 
### Streaming Agnostic Model with k-Nearest Neighbors (SAM-kNN),

samknn = SAMKNNClassifier()
sam_agrawal = stream_classifer(X_agrawal, y_agrawal, samknn, "SAM-kNN", "Agrawal", "(12)")
 
print("Overal Accuracy = %" + str(sam_agrawal[0]) + "\n Run Time (sec) =  " + str(sam_agrawal[1]))
 
### Streaming Random Patches (SRP),

srp = StreamingRandomPatchesClassifier(random_state=1, disable_drift_detection=True, n_estimators = 9)
srp_agrawal = stream_classifer(X_agrawal, y_agrawal, srp, "SRP", "Agrawal", "(13)")
 
print("Overal Accuracy = %" + str(srp_agrawal[0]) + "\n Run Time (sec) =  " + str(srp_agrawal[1]))

### Dynamic Weighted Majority (DWM),

dwm = DynamicWeightedMajorityClassifier(base_estimator=HoeffdingTreeClassifier(), n_estimators = 9)
dwm_agrawal = stream_classifer(X_agrawal, y_agrawal, dwm, "DWM", "Agrawal", "(14)")
 
print("Overal Accuracy = %" + str(dwm_agrawal[0]) + "\n Run Time (sec) =  " + str(dwm_agrawal[1]))

### Ensemble Method,

data = {"samknn": sam_agrawal[3], "arf": arf_agrawal[3], "srp": srp_agrawal[3], "dwm": dwm_agrawal[3]}

ensemble_dt = pd.DataFrame(data)

most_occurings = ensemble_dt.mode(axis=1)
ensemble_dt["ensemble"] = most_occurings[0]

ensemble_dt["index"] = ensemble_dt.index

num_window = len(ensemble_dt)//20

my_windows = []
for i in range(0, len(ensemble_dt), num_window):
    my_windows.append(i)

my_windows = my_windows[:-1]

ensemble_dt["window"] = 0

for i in range(len(my_windows)):
    ensemble_dt.loc[ensemble_dt['index'] >= my_windows[i], 'window'] = i+1

plotter = ensemble_dt.groupby("window")["ensemble"].mean().reset_index()

plt.clf()
fig, ax = plt.subplots(figsize=((5,5)))
ax.plot(plotter["window"], plotter["ensemble"],
marker="v"
, linestyle="--"
, color="r")

ax.set_xticks(range(1,(1+len(plotter["ensemble"]))))
#ax.set_xticklabels(plotter["ensemble"])

ax.set_xlabel("Window number")
ax.set_ylabel("Accuracy")
ax.set_title("(15) Accuracy per Window for " + "Ensemble Method" + " on " + "Agrawal Dataset")

plt.show()
   
ensemble_dt["target"] = y_agrawal
accuracy = round(100*(ensemble_dt[ensemble_dt["ensemble"] == ensemble_dt["target"]].shape[0]/ensemble_dt.shape[0]), 2)

print("Overal Accuracy = %" + str(accuracy) + "\n Run Time (sec) =  " + str(arf_agrawal[1] + dwm_agrawal[1] + srp_agrawal[1]+ sam_agrawal[1]))
 
## For sead dataset,

### Adaptive Random Forest (ARF),

arf = AdaptiveRandomForestClassifier(random_state=1, n_estimators=5)
arf_sead = stream_classifer(X_sead, y_sead, arf, "ARF", "Sead", "(16)")
  
print("Overal Accuracy = %" + str(arf_sead[0]) + "\n Run Time (sec) =  " + str(arf_sead[1]))
 
### Streaming Agnostic Model with k-Nearest Neighbors (SAM-kNN),

samknn = SAMKNNClassifier()
sam_sead = stream_classifer(X_sead, y_sead, samknn, "SAM-kNN", "Sead", "(17)")
 
print("Overal Accuracy = %" + str(sam_sead[0]) + "\n Run Time (sec) =  " + str(sam_sead[1]))

### Streaming Random Patches (SRP),

srp = StreamingRandomPatchesClassifier(random_state=1, disable_drift_detection=True, n_estimators = 3)
srp_sead = stream_classifer(X_sead, y_sead, srp, "SRP", "Sead", "(18)")
 
print("Overal Accuracy = %" + str(srp_sead[0]) + "\n Run Time (sec) =  " + str(srp_sead[1]))
 
### Dynamic Weighted Majority (DWM),

dwm = DynamicWeightedMajorityClassifier(base_estimator=HoeffdingTreeClassifier())
dwm_sead = stream_classifer(X_sead, y_sead, dwm, "DWM", "Sead", "(19)")
 
print("Overal Accuracy = %" + str(dwm_sead[0]) + "\n Run Time (sec) =  " + str(dwm_sead[1]))

### Ensemble Method,

data = {"samknn": sam_sead[3], "arf": arf_sead[3], "srp": srp_sead[3], "dwm": dwm_sead[3]}

ensemble_dt = pd.DataFrame(data)

most_occurings = ensemble_dt.mode(axis=1)
ensemble_dt["ensemble"] = most_occurings[0]

ensemble_dt["index"] = ensemble_dt.index

ensemble_sead = ensemble_dt["ensemble"].to_numpy()

ensemble_dt["target"] = y_sead
ensemble_dt["result"] = 0
ensemble_dt.loc[ensemble_dt["ensemble"] == ensemble_dt["target"], "result"] = 1

num_window = len(ensemble_dt)//20

my_windows = []
for i in range(0, len(ensemble_dt), num_window):
    my_windows.append(i)

my_windows = my_windows[:-1]

ensemble_dt["window"] = 0

for i in range(len(my_windows)):
    ensemble_dt.loc[ensemble_dt['index'] >= my_windows[i], 'window'] = i+1

plotter = ensemble_dt.groupby("window")["result"].mean().reset_index()

plt.clf()
fig, ax = plt.subplots(figsize=((5,5)))
ax.plot(plotter["window"], plotter["result"],
marker="v"
, linestyle="--"
, color="r")


ax.set_xticks(range(1,(1+len(plotter["result"]))))
#ax.set_xticklabels(plotter["ensemble"])


ax.set_xlabel("Window number")
ax.set_ylabel("Accuracy")
ax.set_title("(20) Accuracy per Window for " + "Ensemble Method" + " on " + "Sead Dataset")

plt.show()
  
ensemble_dt["target"] = y_sead
accuracy = round(100*(ensemble_dt[ensemble_dt["ensemble"] == ensemble_dt["target"]].shape[0]/ensemble_dt.shape[0]), 2)

print("Overal Accuracy = %" + str(accuracy) + "\n Run Time (sec) =  " + str(arf_sead[1] + dwm_sead[1] + srp_sead[1]+ sam_sead[1]))

#%%
results = np.concatenate((y_electric, y_spam, y_agrawal, y_sead), axis=0)

pred_arf = np.concatenate((arf_el[3], arf_spam[3], arf_agrawal[3], arf_sead[3]), axis=0)
pred_sam = np.concatenate((sam_el[3], sam_spam[3], sam_agrawal[3], sam_sead[3]), axis=0)
pred_srp = np.concatenate((srp_el[3], srp_spam[3], srp_agrawal[3], srp_sead[3]), axis=0)
pred_dwm = np.concatenate((dwm_el[3], dwm_spam[3], dwm_agrawal[3], dwm_sead[3]), axis=0)
pred_ensemble = np.concatenate(ensemble_electric, ensemble_spam, ensemble_agrawal, ensemble_sead)

def alt_res(pred, method):
  # Confusion Matrix
  cm = confusion_matrix(method, pred)
  print("Confusion Matrix for the:" + method)
  print(cm)
  
  # Precision
  precision = precision_score(results, pred)
  print("Precision for the " + method + " = " + str(precision))
  
  # Recall
  recall = recall_score(results, pred)
  print("Recall for the "+ method + " = " + str(recall))
  
  # F-measure
  f_measure = f1_score(results, pred)
  print("F-measure for the " + method + " = " + str(f_measure))
  
  # Specificity
  specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])
  print("Specificity for the " + method + " = " + str(specificity))


alt_res("ARF", pred_arf)

alt_res("SAMkNN", pred_sam)

alt_res("SRP", pred_srp)

alt_res("DWM", pred_dwm)

alt_res("Ensemble", pred_ensemble)
 